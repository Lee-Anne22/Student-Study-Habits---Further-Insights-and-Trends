---
Title: Student Study Habits 
Subtitle: Further Insights and Trends
Author: Lee-Anne van der Merwe
format: ipynb
code-fold: true
jupyter: python3
kernal: base
---

# Data Collection and Preparation

## Collection of Data:

The data collected for this project is provided by Kaggle and thorough preparation of this data were done for machine learning models.

```{python}
#Importing all necessary programs
def import_study_libs():
    import numpy as np
    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import plotly.graph_objects as go
    import plotly.io as pio
    import sklearn as sk
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    from sklearn.model_selection import GridSearchCV
    from sklearn.model_selection import StratifiedKFold
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.tree import plot_tree
    from sklearn.metrics import accuracy_score
    from sklearn.metrics import confusion_matrix
    from sklearn.metrics import classification_report
    from sklearn.metrics import make_scorer
    import lime as lime
    import shap as shap
    from IPython.display import Image
    return {"np": np, "pd": pd, "sns": sns, "plt": plt, "go": go, "pio": pio, "sk": sk, "StandardScaler": StandardScaler, "train_test_split": train_test_split, "GridSearchCV": GridSearchCV, "StratifiedKFold": StratifiedKFold,
            "DecisionTreeClassifier": DecisionTreeClassifier, "plot_tree": plot_tree, "accuracy_score": accuracy_score, "confusion_matrix": confusion_matrix,
            "classification_report":classification_report, "make_scorer": make_scorer, "lime": lime, "shap": shap, "Image": Image}

# Loading the data set
original_file= "student_habits_performance.csv"
def load_study_data_original():
    try:
        libs = import_study_libs()
        pd = libs["pd"]

        # Use correct delimiter and updated error handling
        df = pd.read_csv(original_file, sep=';', encoding='utf-8', on_bad_lines='skip')

        # Normalize column names
        df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")
        df_missing = df.fillna(df.mean(numeric_only=True))
        df_duplicates = df_missing.drop_duplicates()

        df_clean = df_duplicates[
        (df_duplicates["sleep_hours"] + df_duplicates["social_media_hours"] +
         df_duplicates["netflix_hours"] + df_duplicates["study_hours_per_day"] <= 24) &
        (df_duplicates["sleep_hours"] >= 0) &
        (df_duplicates["age"].between(16, 24))
    ]

        print("Data Cleaned and Loaded Successfully!")
      
        return df_clean
    except FileNotFoundError:
        print(f"File not found: {original_file}")
        return None
        
```

## Preparation of Data:

Data is prepped by removing missing values, selecting the age range, encoding categorical values and normalising numeric variables.

```{python}
# Handle missing Values and duplicates:
def study_clean():
    df = load_study_data_original()
    if df is None:
        return None  # Exit early if loading failed

    libs = import_study_libs()
    pd = libs["pd"]
    np = libs["np"]
#Print column headings, shape, statistical data and info on null values
    
    print ("Column Headings:")
    for col in df.columns:
        print(col)
    
    print(f"Data shape: {df.shape}\n")
    print(f"Data Statistics:\n{df.describe()}\n")
    print(f"Data information: {df.info()}")

##Normalisation and standardisation of categories for machine models

def standardize_features(target_column="exam_score", id_column="student_id", save=True):
    #import libraries
    libs = import_study_libs()
    pd = libs["pd"]
    scaler = libs["StandardScaler"]

    # Load and clean data
    df = load_study_data_original()
    if df is None:
        print("Data loading failed. Cannot proceed with standardization.")
        return None

    df_encoded = df.copy()

    # Binary encoding
    df_encoded["part_time_job_encoded"] = df_encoded["part_time_job"].map({"No": 0, "Yes": 1})
    df_encoded["extracurricular_encoded"] = df_encoded["extracurricular_participation"].map({"No": 0, "Yes": 1})

    # Ordinal encoding
    df_encoded["internet_quality_encoded"] = df_encoded["internet_quality"].map({"poor": 0, "average": 1, "good": 2})
    df_encoded["diet_quality_encoded"] = df_encoded["diet_quality"].map({"poor": 0, "average": 1, "good": 2})

    # Define modeling features
    modeling_features = [
        "age", "study_hours_per_day", "social_media_hours", "netflix_hours",
        "attendance_percentage", "sleep_hours", "mental_health_rating",
        "exercise_frequency", "internet_quality_encoded", "diet_quality_encoded",
        "part_time_job_encoded", "extracurricular_encoded", target_column
    ]

    # Check for missing columns
    missing_cols = [col for col in modeling_features if col not in df_encoded.columns]
    if missing_cols:
        print(f"Missing columns in dataset: {missing_cols}")
        return None, None, None

    # Separate features and target
    X = df_encoded[modeling_features].drop(columns=[target_column])
    y = df_encoded[target_column]
    X_scaled = scaler().fit_transform(X)

    # Save enriched dataset
    if save:
        df_encoded.to_csv("student_habits_encoded.csv", index=False)
        print("Encoded dataset saved as 'student_habits_encoded.csv'")

    return X_scaled, y, df_encoded
```

```{python}
#New function to load new encoded csv
def load_study_data():    
    try:
        libs= import_study_libs()
        pd= libs["pd"]
        df= pd.read_csv("student_habits_encoded.csv", sep=',')
        return df
    except FileNotFoundError:
        print (f"File not found!: {file}")
        return None

```

# Data Exploration and Model Building

## Statistical Analysis:

The data was first explored by applied statistical in three ways:

-   Mean study time by Health Tier

-   Correlation between sleep and exam scores

-   Outlier detection

## Data Exploration:

Data were explored and the following plots were obtained:

-   Scatter plot

    -   The correlation between exam score and internet quality, sleep hours and exercise frequency

-   Stacked bar plot

    -   The difference in categories between the following age groups: 16-18 years, 19-20 years, 21-22 years and 23-24 years.

-   Box/Violin plots

    -   Mental Health rating per age group: 16-18 years, 19-20 years, 21-22 years and 23-24 years.

-   Heatmaps

    -   To gain multivariate insights between categories

-   Parallel Coordinates plots

    -   

-   Radar Charts

    -   The difference in time spent between the following age groups: 16-18 years, 19-20 years, 21-22 years and 23-24 years.

        -   Amount of study hours - study hours

        -   Amount of time spent on social media - social media hours

        -   Amount of time spent on Netflix - netflix hours

        -   Amount of time spent on sleep - sleep hours

```{python}
def Scatterplots():
#Import libraries
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    np= libs["np"]
    Image= libs["Image"]
#Create three scatter plots
# Scatter plot : Subplot (1) Exam score vs Study hours per day
    # Plot Style
    sns.set_style("whitegrid")
    
    # Create figure and subplots
    fig, axs = plt.subplots(1, 3, figsize=(15, 8))  # 1 row, 3 columns
    #Extracting data and giving them variables
    x1= df['study_hours_per_day']
    x2=df["sleep_hours"]
    x3=df["exercise_frequency"]
    y=df["exam_score"]

    x1_sorted = np.sort(x1)
    coefficients1 = np.polyfit(x1, y, 1)
    trendline_function = np.poly1d(coefficients1)
    axs[0].plot(x1, trendline_function(x1), color='red', linestyle='--', label='Trendline')
    axs[0].scatter(x1, y, color='blue')
    axs[0].set_xlabel("Study Hours per Day (hours)")
    axs[0].set_ylabel("Exam Score")
    axs[0].set_title("Exam Scores VS Study Hours per Day", fontsize=12)
    correlation1 = np.corrcoef(x1, y)[0, 1]
    print(f"Correlation between study hours per day and exam score: {correlation1:.2f}")
 
    # Subplot(2) Exam score vs Sleep
    x2_sorted = np.sort(x2)
    coefficients2 = np.polyfit(x2, y, 1)
    trendline_function2 = np.poly1d(coefficients2)
    axs[1].plot(x2, trendline_function2(x2), color='red', linestyle='--', label='Trendline')
    axs[1].scatter(x2, y, color='green')
    axs[1].set_xlabel("Sleep Hours (hours)")
    axs[1].set_ylabel("Exam Score")
    axs[1].set_title("Exam Scores VS Sleep Hours", fontsize=12)
    correlation2 = np.corrcoef(x2, y)[0, 1]
    print(f"Correlation between sleep and exam score: {correlation2:.2f}")
    # Subplot (3): Exam score vs Exercise Frequency
    x3_sorted = np.sort(x3)
    coefficients3 = np.polyfit(x3, y, 1)
    trendline_function3 = np.poly1d(coefficients3)
    axs[2].plot(x3, trendline_function3(x3), color='red', linestyle='--', label='Trendline')
    axs[2].scatter(x3, y, color='orange')
    axs[2].set_xlabel("Exercise Frequency (per day)")
    axs[2].set_ylabel("Exam Score")
    axs[2].set_title("Exam Scores VS Exercise Frequency", fontsize=12)
    correlation3 = np.corrcoef(x3, y)[0, 1]
    print(f"Correlation between exercise frequency and exam score: {correlation3:.2f}")
    plt.tight_layout()
    
    fig.savefig('ExamScore_vs_Study_Habits.png') #saving plot as png
    plt.show()

```

```{python}
#Stacked bar plot1: Difference in age groups
def stackedbar():
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    Image= libs["Image"]

    # Group by gender and internet quality, then calculate average exam score
    
    #grouped_data= df.groupby(['gender','exam_score'])['internet_quality'].size().unstack(fill_value=0)
    ordered_quality = ['Poor', 'Average', 'Good']
    grouped_data = df.groupby(['gender', 'internet_quality'])['exam_score'].mean().unstack()
    grouped_data = grouped_data[ordered_quality]

    #create the plot     
    grouped_data.plot(kind='bar', stacked=True, figsize=(10, 6), cmap='rainbow')
    width= 0.5
    # Labels and title
    plt.xlabel('Gender')
    plt.ylabel('Average Exam Score')
    plt.title('Exam Scores by Gender and Internet Quality')
    plt.legend(title='Internet Quality')
    plt.ylim(0, 100)  # Since scores are out of 100
    plt.tight_layout()
    plt.savefig('Exam Scores by Gender and Internet quality.png')
    plt.show()

    
```

```{python}
#Violin plot: Mental Health rating per age group: 16-18 years, 19-20 years, 21-22 years and 23-24 years
def violinplot():
    #import libraries
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    pd= libs["pd"]
    Image= libs["Image"]

    #Extract data and make age groups through the use of bins
    bins = [15, 18, 20, 22, 24]
    labels = ['16-18', '19-20', '21-22', '23-24']
    df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=True)
    
    #create plot
    fig, axes= plt.subplots(figsize=(10,5))
    #make it a violinplot
    sns.violinplot(x= 'age_group', y='mental_health_rating', data=df, ax=axes, palette='rainbow', hue='age_group', legend=False)
    axes.set_title("Mental Health Rating Across Age Groups")
    axes.set_xlabel('Age Groups')
    axes.set_ylabel('Mental Health Rating')
    plt.tight_layout()
    
    #save figure and show
    fig.savefig('mental_health_rating_across_age_groups.png')
    plt.show()
```

```{python}
#Heatmap
def heatmap():
    #import libraries
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    Image= libs["Image"]

    #cleaning to prep data for the heatmap by removing categorical fields
    heatdata=df.drop(['student_id', 'gender', 'part_time_job', 'diet_quality', 'internet_quality', 'parental_education_level', 'extracurricular_participation'], axis='columns')
    
    
    #create plot
    fig, axes= plt.subplots(figsize=(10,5))
    #make it a heatmap
    sns.heatmap(heatdata.corr(), cmap='rainbow', annot= True)
    axes.set_title('Correlation Of Numeric Study Habits')
    #save and show figure
    plt.tight_layout()
    fig.savefig('Heatmap.png')
    plt.show()
```

```{python}
#Parallel Coordinates plot
```

```{python}
#Radar Charts
#comparison of time spent in a day
def radarplot():
    #load data
    df = load_study_data()
    if df is None:
        return None 
    #load libraries
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    go= libs["go"]
    pio= libs["pio"]
    Image= libs["Image"]
    # pio renderer set for radar plot in Quarto but converting to ipynb
    pio.renderers.default = 'notebook'
    # extract data and get the averages
    selected_columns = ['study_hours_per_day', 'social_media_hours', 'netflix_hours', 'sleep_hours']
    avg_values = df[selected_columns].mean().tolist()
    categories = selected_columns.copy()

    #Closing the loop
    categories += [categories[0]]
    avg_values += [avg_values[0]]

    # Create radar plot
    fig = go.Figure(
    data= go.Scatterpolar(
        r=avg_values,
        theta=categories,
        fill='toself',
        name='Average Time Spent (hours)'))
    
    fig.update_layout(
    margin=dict(l=20, r=20, t=40, b=20),  # reduce left, right, top, bottom margins
    polar=dict(
        radialaxis=dict(visible=True, range=[0, max(avg_values) + 1])
    ),
    title=dict(text='Radar Plot of Average Daily Time Spent', x=0.5),  # center title
    showlegend=True
)

    fig.show()


```

```{python}
#calling all functions
def main():
    functions= [import_study_libs, load_study_data_original, standardize_features, load_study_data, study_clean, Scatterplots, stackedbar, violinplot, heatmap, radarplot] 
    for func in functions:
        func()

if __name__== '__main__':
    main()
```

## Model Building:

The linear regression model and decision tree model were trained for this project:

##### Linear Regression Model

The following categories were considered in the linear regression model:

-   Study hours
-   Sleep hours
-   Social Media hours
-   Netflix hours
-   Exercise frequency
-   Predicted Exam Score

The categories expected to be most profitable were increased to predict the impact on exam score. These categories were: sleep hours, study hours and exercise frequency.

```{python}
# Excluding categorical data and checking correlation
def exclude_cat():
    df = load_study_data()
    if df is None:
        return None
    libs = import_study_libs()
    plt = libs["plt"]
    sns = libs["sns"]
    np = libs["np"]

    # Select only numeric columns
    numeric_df = df.select_dtypes(include=[np.number])

    # Check if any numeric columns exist
    if numeric_df.empty:
        print("No numeric columns found for correlation.")
        return

    # Compute and print correlation matrix
    print("Correlation matrix:")
    print(numeric_df.corr())
exclude_cat()


```

##### Decision Tree

A decision tree was utilised to predict whether a student would obtain an exam score above 75% or not.

#Note to self: Need to change the following categories:

-   part-time -\> 0 or 1 (binary class)

-   diet quality (multi-class)

-   parental education (multi-class)

-   internet quality (multi-class)

-   extracurricular activity -\> 0 or 1 (binary class)

```{python}

```