---
Title: Student Study Habits 
Subtitle: Further Insights and Trends
Author: Lee-Anne van der Merwe
format: ipynb
code-fold: true
jupyter: python3
kernal: base
---

# Data Collection and Preparation

## Collection of Data:

The data collected for this project is provided by Kaggle and thorough preparation of this data were done for machine learning models.

```{python}
#Importing all necessary programs
def import_study_libs():
    import numpy as np
    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import plotly.graph_objects as go
    import plotly.io as pio
    import sklearn as sk
    from sklearn.model_selection import train_test_split
    from sklearn.model_selection import GridSearchCV
    from sklearn.model_selection import StratifiedKFold
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.tree import plot_tree
    from sklearn.metrics import accuracy_score
    from sklearn.metrics import confusion_matrix
    from sklearn.metrics import classification_report
    from sklearn.metrics import make_scorer
    import lime as lime
    import shap as shap
    from IPython.display import Image
    return {"np": np, "pd": pd, "sns": sns, "plt": plt, "go": go, "pio": pio, "train_test_split": train_test_split, "GridSearchCV": GridSearchCV, "StratifiedKFold": StratifiedKFold,
            "DecisionTreeClassifier": DecisionTreeClassifier, "plot_tree": plot_tree, "accuracy_score": accuracy_score, "confusion_matrix": confusion_matrix,
            "classification_report":classification_report, "make_scorer": make_scorer, "lime": lime, "shap": shap, "Image": Image}

# Loading the data set
file= "student_habits_performance.csv"
def load_study_data():
    try:
        libs= import_study_libs()
        pd= libs["pd"]
        df= pd.read_csv(file, sep=';')
        df.columns=df.columns.str.strip() #To clean up data
        print ("Data Loaded Succesfully!")
        return df
    except FileNotFoundError:
        print (f"File not found!: {file}")
        return None
        
```

## Preparation of Data:

Data is prepped by removing missing values, selecting the age range, encoding categorical values and normalising numeric variables.

```{python}
# Handle missing Values and duplicates:
def study_clean():
    df = load_study_data()
    if df is None:
        return None  # Exit early if loading failed

    libs = import_study_libs()
    pd = libs["pd"]
    np = libs["np"]

    print(f"Data size:\n{df.head()}\n")
    print(f"Data shape: {df.shape}\n")
    print(f"Data Statistics:\n{df.describe()}\n")

    df_missing = df.fillna(df.mean(numeric_only=True))
    df_duplicates = df_missing.drop_duplicates()

    df_clean = df_duplicates[
        (df_duplicates["sleep_hours"] + df_duplicates["social_media_hours"] +
         df_duplicates["netflix_hours"] + df_duplicates["study_hours_per_day"] <= 24) &
        (df_duplicates["sleep_hours"] >= 0) &
        (df_duplicates["age"].between(16, 24))
    ]

    print("Data preprocessed and cleaned!")
    return df_clean
    

```

# Data Exploration and Model Building

## Statistical Analysis:

The data was first explored by applied statistical in three ways:

-   Mean study time by Health Tier

-   Correlation between sleep and exam scores

-   Outlier detection

```{python}
# Statistical Analysis
def stats():
    data= study_clean()
    df=data["df_clean"]
    #Get data statistical analysis after cleaning
    return data.columns, data.describe()


```

## Data Exploration:

Data were explored and the following plots were obtained:

-   Scatter plot

    -   The correlation between exam score and internet quality, sleep hours and exercise frequency

-   Stacked bar plot

    -   The difference in categories between the following age groups: 16-18 years, 19-20 years, 21-22 years and 23-24 years.

-   Box/Violin plots

    -   Mental Health rating per age group: 16-18 years, 19-20 years, 21-22 years and 23-24 years.

-   Heatmaps

    -   To gain multivariate insights between categories

-   Parallel Coordinates plots

    -   

-   Radar Charts

    -   The difference in time spent between the following age groups: 16-18 years, 19-20 years, 21-22 years and 23-24 years.

        -   Amount of study hours - study hours

        -   Amount of time spent on social media - social media hours

        -   Amount of time spent on Netflix - netflix hours

        -   Amount of time spent on sleep - sleep hours

```{python}
def Scatterplots():
#Import libraries
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    np= libs["np"]
    Image= libs["Image"]
#Create three scatter plots
# Scatter plot : Subplot (1) Exam score vs Study hours per day
    # Plot Style
    sns.set_style("whitegrid")
    
    # Create figure and subplots
    fig, axs = plt.subplots(1, 3, figsize=(15, 8))  # 1 row, 3 columns
    #Extracting data and giving them variables
    x1= df['study_hours_per_day']
    x2=df["sleep_hours"]
    x3=df["exercise_frequency"]
    y=df["exam_score"]

    x1_sorted = np.sort(x1)
    coefficients1 = np.polyfit(x1, y, 1)
    trendline_function = np.poly1d(coefficients1)
    axs[0].plot(x1, trendline_function(x1), color='red', linestyle='--', label='Trendline')
    axs[0].scatter(x1, y, color='blue')
    axs[0].set_xlabel("Study Hours per Day (hours)")
    axs[0].set_ylabel("Exam Score")
    axs[0].set_title("Exam Scores VS Study Hours per Day", fontsize=12)
    correlation1 = np.corrcoef(x1, y)[0, 1]
    print(f"Correlation between study hours per day and exam score: {correlation1:.2f}")
 
    # Subplot(2) Exam score vs Sleep
    x2_sorted = np.sort(x2)
    coefficients2 = np.polyfit(x2, y, 1)
    trendline_function2 = np.poly1d(coefficients2)
    axs[1].plot(x2, trendline_function2(x2), color='red', linestyle='--', label='Trendline')
    axs[1].scatter(x2, y, color='green')
    axs[1].set_xlabel("Sleep Hours (hours)")
    axs[1].set_ylabel("Exam Score")
    axs[1].set_title("Exam Scores VS Sleep Hours", fontsize=12)
    correlation2 = np.corrcoef(x2, y)[0, 1]
    print(f"Correlation between sleep and exam score: {correlation2:.2f}")
    # Subplot (3): Exam score vs Exercise Frequency
    x3_sorted = np.sort(x3)
    coefficients3 = np.polyfit(x3, y, 1)
    trendline_function3 = np.poly1d(coefficients3)
    axs[2].plot(x3, trendline_function3(x3), color='red', linestyle='--', label='Trendline')
    axs[2].scatter(x3, y, color='orange')
    axs[2].set_xlabel("Exercise Frequency (per day)")
    axs[2].set_ylabel("Exam Score")
    axs[2].set_title("Exam Scores VS Exercise Frequency", fontsize=12)
    correlation3 = np.corrcoef(x3, y)[0, 1]
    print(f"Correlation between exercise frequency and exam score: {correlation3:.2f}")
    plt.tight_layout()
    
    fig.savefig('ExamScore_vs_Study_Habits.png') #saving plot as png
    plt.show()

```

```{python}
#Stacked bar plot1: Difference in age groups
def stackedbar():
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    Image= libs["Image"]

```

```{python}
#Violin plot: Mental Health rating per age group: 16-18 years, 19-20 years, 21-22 years and 23-24 years
def violinplot():
    #import libraries
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    pd= libs["pd"]
    Image= libs["Image"]

    #Extract data and make age groups through the use of bins
    bins = [15, 18, 20, 22, 24]
    labels = ['16-18', '19-20', '21-22', '23-24']
    df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=True)
    
    #create plot
    fig, axes= plt.subplots(figsize=(10,5))
    #make it a violinplot
    sns.violinplot(x= 'age_group', y='mental_health_rating', data=df, ax=axes, palette='rainbow', hue='age_group', legend=False)
    axes.set_title("Mental Health Rating Across Age Groups")
    axes.set_xlabel('Age Groups')
    axes.set_ylabel('Mental Health Rating')
    plt.tight_layout()
    
    #save figure and show
    fig.savefig('mental_health_rating_across_age_groups.png')
    plt.show()
```

```{python}
#Heatmap
def heatmap():
    #import libraries
    df = load_study_data()
    if df is None:
        return None 
        
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    Image= libs["Image"]

    #cleaning to prep data for the heatmap by removing categorical fields
    heatdata=df.drop(['student_id', 'gender', 'part_time_job', 'diet_quality', 'internet_quality', 'parental_education_level', 'extracurricular_participation'], axis='columns')
    
    
    #create plot
    fig, axes= plt.subplots(figsize=(10,5))
    #make it a heatmap
    sns.heatmap(heatdata.corr(), cmap='rainbow', annot= True)
    axes.set_title('Correlation Of Numeric Study Habits')
    #save and show figure
    plt.tight_layout()
    fig.savefig('Heatmap.png')
    plt.show()
```

```{python}
#Parallel Coordinates plot
```

```{python}
#Radar Charts
#comparison of time spent in a day
def radarplot():
    #load data
    df = load_study_data()
    if df is None:
        return None 
    #load libraries
    libs = import_study_libs()
    plt= libs["plt"]
    sns= libs["sns"]
    go= libs["go"]
    pio= libs["pio"]
    Image= libs["Image"]
    # pio renderer set for radar plot in Quarto but converting to ipynb
    pio.renderers.default = 'notebook'
    # extract data and get the averages
    selected_columns = ['study_hours_per_day', 'social_media_hours', 'netflix_hours', 'sleep_hours']
    avg_values = df[selected_columns].mean().tolist()
    categories = selected_columns.copy()

    #Closing the loop
    categories += [categories[0]]
    avg_values += [avg_values[0]]

    # Create radar plot
    fig = go.Figure(
    data= go.Scatterpolar(
        r=avg_values,
        theta=categories,
        fill='toself',
        name='Average Time Spent (hours)'))
    
    fig.update_layout(
    margin=dict(l=20, r=20, t=40, b=20),  # reduce left, right, top, bottom margins
    polar=dict(
        radialaxis=dict(visible=True, range=[0, max(avg_values) + 1])
    ),
    title=dict(text='Radar Plot of Average Daily Time Spent', x=0.5),  # center title
    showlegend=True
)

    fig.show()


```

```{python}
#calling all functions
def main():
    functions= [import_study_libs, load_study_data, study_clean, Scatterplots, violinplot, heatmap, radarplot] 
    for func in functions:
        func()

if __name__== '__main__':
    main()
```

## Model Building:

The linear regression model and decision tree model were trained for this project:

##### Linear Regression Model

The following categories were considered in the linear regression model:

-   Study hours
-   Sleep hours
-   Social Media hours
-   Netflix hours
-   Exercise frequency
-   Predicted Exam Score

The categories expected to be most profitable were increased to predict the impact on exam score. These categories were: sleep hours, study hours and exercise frequency.

```{python}

```

##### Decision Tree

A decision tree was utilised to predict whether a student would obtain an exam score above 75% or not.

#Note to self: Need to change the following categories:

-   part-time -\> 0 or 1 (binary class)

-   diet quality (multi-class)

-   parental education (multi-class)

-   internet quality (multi-class)

-   extracurricular activity -\> 0 or 1 (binary class)

```{python}

```